{
	"name": "SKLearn-Predict",
	"properties": {
		"folder": {
			"name": "_adhoc"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "threedot0",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 1,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "1",
				"spark.autotune.trackingId": "b6e4161b-2479-4cdb-a3c3-ee62be0afc4e"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e4e06275-58d1-4081-8f1b-be12462eb701/resourceGroups/wplushiramsynapse/providers/Microsoft.Synapse/workspaces/wplushiramsynapse/bigDataPools/threedot0",
				"name": "threedot0",
				"type": "Spark",
				"endpoint": "https://wplushiramsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/threedot0",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 5,
				"cores": 8,
				"memory": 56,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import fsspec\r\n",
					"import pandas\r\n",
					"from fsspec.core import split_protocol\r\n",
					"\r\n",
					"fsspec_handle = fsspec.open('abfss://wplushiramsynapsefs@wplushiramsynapseadlsv2.dfs.core.windows.net/dominicks_OJ_train.csv')\r\n",
					"\r\n",
					"with fsspec_handle.open() as f:\r\n",
					"    train_df = pandas.read_csv(f)"
				],
				"attachments": null,
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# LinearRegresssion\r\n",
					"fails due to schema of dataset"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import os\r\n",
					"import shutil\r\n",
					"import mlflow\r\n",
					"import json\r\n",
					"from mlflow.utils import model_utils\r\n",
					"import numpy as np\r\n",
					"import pandas as pd\r\n",
					"from sklearn.linear_model import LinearRegression\r\n",
					"\r\n",
					"class LinearRegressionModel():\r\n",
					"    _ARGS_FILENAME = 'args.json'\r\n",
					"    FEATURES_KEY = 'features'\r\n",
					"    TARGETS_KEY = 'targets'\r\n",
					"    TARGETS_PRED_KEY = 'targets_pred'\r\n",
					"\r\n",
					"    def __init__(self, fit_intercept, nb_input_features=9, nb_output_features=1):\r\n",
					"        self.fit_intercept = fit_intercept\r\n",
					"        self.nb_input_features = nb_input_features\r\n",
					"        self.nb_output_features = nb_output_features\r\n",
					"\r\n",
					"    def get_args(self):\r\n",
					"        args = {\r\n",
					"            'nb_input_features': self.nb_input_features,\r\n",
					"            'nb_output_features': self.nb_output_features,\r\n",
					"            'fit_intercept': self.fit_intercept\r\n",
					"        }\r\n",
					"        return args\r\n",
					"\r\n",
					"    def create_model(self):\r\n",
					"        self.model = LinearRegression(fit_intercept=self.fit_intercept)\r\n",
					"\r\n",
					"    def train(self, dataset):\r\n",
					"        features = np.stack([sample for sample in iter(\r\n",
					"            dataset[LinearRegressionModel.FEATURES_KEY])], axis=0)\r\n",
					"        targets = np.stack([sample for sample in iter(\r\n",
					"            dataset[LinearRegressionModel.TARGETS_KEY])], axis=0)\r\n",
					"        self.model.fit(features, targets)\r\n",
					"\r\n",
					"    def predict(self, dataset):\r\n",
					"        features = np.stack([sample for sample in iter(\r\n",
					"            dataset[LinearRegressionModel.FEATURES_KEY])], axis=0)\r\n",
					"        targets_pred = self.model.predict(features)\r\n",
					"        return targets_pred\r\n",
					"\r\n",
					"    def save(self, path):\r\n",
					"        if os.path.exists(path):\r\n",
					"            shutil.rmtree(path)\r\n",
					"        mlflow.sklearn.save_model(self.model, path)\r\n",
					"        self._save_args(path)\r\n",
					"\r\n",
					"    def _save_args(self, path):\r\n",
					"        args_filename = os.path.join(path, LinearRegressionModel._ARGS_FILENAME)\r\n",
					"        with open(args_filename, 'w') as f:\r\n",
					"            args = self.get_args()\r\n",
					"            json.dump(args, f)\r\n",
					"\r\n",
					"def train(train_df, output_model_path):\r\n",
					"    print(f\"Start to train LinearRegressionModel.\")\r\n",
					"\r\n",
					"    dataset = train_df.to_numpy()\r\n",
					"    datasets = {}\r\n",
					"    datasets['targets'] = dataset[:, -1]\r\n",
					"    datasets['features'] = dataset[:, :9]\r\n",
					"\r\n",
					"    model_class = LinearRegressionModel(fit_intercept=10)\r\n",
					"    with mlflow.start_run(nested=True) as run:\r\n",
					"        model_class.create_model()\r\n",
					"        model_class.train(datasets)\r\n",
					"        model_class.save(output_model_path)\r\n",
					"        print(model_class.predict(datasets))\r\n",
					"\r\n",
					"train(train_df, './artifacts/output')\r\n",
					""
				],
				"attachments": null,
				"execution_count": 6
			}
		]
	}
}
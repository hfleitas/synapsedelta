{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "spark.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "case class Data(key: String, value: String)\r\n",
        "\r\n",
        "case class ChangeData(key: String, newValue: String, deleted: Boolean, time: Long) {\r\n",
        "  assert(newValue != null ^ deleted)\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "val target = Seq(\r\n",
        "  Data(\"a\", \"0\"),\r\n",
        "  Data(\"b\", \"1\"),\r\n",
        "  Data(\"c\", \"2\"),\r\n",
        "  Data(\"d\", \"3\")\r\n",
        ").toDF()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "sql(\"drop table if exists target\")\r\n",
        "target.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"target\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "val targetDF = spark.sqlContext.sql(\"select * from target\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## New API docs\r\n",
        "https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/synapse-spark-sql-pool-import-export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "//Add required imports\r\n",
        "import org.apache.spark.sql.DataFrame\r\n",
        "import org.apache.spark.sql.SaveMode\r\n",
        "import com.microsoft.spark.sqlanalytics.utils.Constants\r\n",
        "import org.apache.spark.sql.SqlAnalyticsConnector._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "//new write options\r\n",
        "val writeOptions:Map[String, String] = Map(Constants.SERVER -> \"wplushiramsynapse.sql.azuresynapse.net\", \r\n",
        "Constants.TEMP_FOLDER -> \"abfss://wplushiramsynapsefs@wplushiramsynapseadlsv2.dfs.core.windows.net/synapse/workspaces/wplushiramsynapse/temp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "//Set up optional callback/feedback function that can receive post write metrics of the job performed.\r\n",
        "var errorDuringWrite:Option[Throwable] = None\r\n",
        "val callBackFunctionToReceivePostWriteMetrics: (Map[String, Any], Option[Throwable]) => Unit =\r\n",
        "    (feedback: Map[String, Any], errorState: Option[Throwable]) => {\r\n",
        "    println(s\"Feedback map - ${feedback.map{case(key, value) => s\"$key -> $value\"}.mkString(\"{\",\",\\n\",\"}\")}\")\r\n",
        "    errorDuringWrite = errorState\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "//write to Synapse Dedicated SQL Pool (note - default SaveMode is set to ErrorIfExists)\r\n",
        "targetDF.\r\n",
        "    write.\r\n",
        "    options(writeOptions).\r\n",
        "    mode(SaveMode.Overwrite).\r\n",
        "    synapsesql(tableName = \"wplussynapsedw.dbo.target\", \r\n",
        "                tableType = Constants.INTERNAL, //For external table type value is Constants.EXTERNAL\r\n",
        "                location = None, //Not required for writing to an internal table\r\n",
        "                callBackHandle = Some(callBackFunctionToReceivePostWriteMetrics))\r\n",
        "\r\n",
        "//If write request has failed, raise an error and fail the Cell's execution.\r\n",
        "if(errorDuringWrite.isDefined) throw errorDuringWrite.get   "
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_spark",
      "display_name": "scala"
    },
    "language_info": {
      "name": "scala"
    }
  }
}